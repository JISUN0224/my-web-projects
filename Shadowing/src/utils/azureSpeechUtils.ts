import * as SpeechSDK from 'microsoft-cognitiveservices-speech-sdk';
import { prepareAudioForAzure } from './audioUtils';

// Azure Speech Services ì„¤ì • - Vite í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
const getSpeechConfig = () => {
  // Vite í™˜ê²½ë³€ìˆ˜ ì§ì ‘ ì ‘ê·¼
  const apiKey = (import.meta as any).env.VITE_AZURE_SPEECH_KEY;
  const region = (import.meta as any).env.VITE_AZURE_SPEECH_REGION;
  const endpoint = (import.meta as any).env.VITE_AZURE_SPEECH_ENDPOINT;
  
  console.log('ğŸ” í™˜ê²½ë³€ìˆ˜ í™•ì¸:', {
    apiKey: apiKey ? `âœ… ì„¤ì •ë¨ (${apiKey.substring(0, 10)}...)` : 'âŒ ì„¤ì •ë˜ì§€ ì•ŠìŒ',
    region: region ? `âœ… ì„¤ì •ë¨ (${region})` : 'âŒ ì„¤ì •ë˜ì§€ ì•ŠìŒ',
    endpoint: endpoint ? `âœ… ì„¤ì •ë¨ (${endpoint})` : 'âŒ ì„¤ì •ë˜ì§€ ì•ŠìŒ'
  });
  
  if (!apiKey || !region) {
    console.error('í•„ìš”í•œ í™˜ê²½ë³€ìˆ˜:', 'VITE_AZURE_SPEECH_KEY, VITE_AZURE_SPEECH_REGION');
    throw new Error('Azure Speech Services ì„¤ì •ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.');
  }
  
  // Azure Speech Config ìƒì„±
  const speechConfig = SpeechSDK.SpeechConfig.fromSubscription(apiKey, region);
  
  // TTS ìŒì„± ì„¤ì • - ë‚¨ì ë‰´ìŠ¤ ëª©ì†Œë¦¬
  speechConfig.speechSynthesisVoiceName = 'zh-CN-YunxiNeural';
  
  return speechConfig;
};

// Azure Speech Assessment APIë¥¼ ì‚¬ìš©í•œ ë°œìŒ í‰ê°€
export const evaluatePronunciationWithAzure = async (
  audioBlob: Blob,
  referenceText: string
): Promise<any> => {
  try {
    console.log('ğŸ” Azure Speech Assessment ì‹œì‘...');
    
    // Speech Config ê°€ì ¸ì˜¤ê¸°
    const speechConfig = getSpeechConfig();
    if (!speechConfig) {
      throw new Error('Azure Speech Services ì„¤ì •ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.');
    }
    
    // ì˜¤ë””ì˜¤ë¥¼ Azure SDKì— ë§ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    const wavBlob = await prepareAudioForAzure(audioBlob);
    console.log('âœ… ì˜¤ë””ì˜¤ ë³€í™˜ ì™„ë£Œ:', wavBlob.size, 'bytes');
    
    // Pronunciation Assessment ì„¤ì •
    const pronunciationAssessmentConfig = new SpeechSDK.PronunciationAssessmentConfig(
      referenceText,
      SpeechSDK.PronunciationAssessmentGradingSystem.HundredMark,
      SpeechSDK.PronunciationAssessmentGranularity.Phoneme,
      true
    );
    
    // Speech Recognizer ìƒì„± - WAV Blobì„ Fileë¡œ ë³€í™˜
    const audioFile = new File([wavBlob], 'recording.wav', { type: 'audio/wav' });
    const audioConfig = SpeechSDK.AudioConfig.fromWavFileInput(audioFile);
    
    // ì¤‘êµ­ì–´ ì–¸ì–´ ì„¤ì • ì¶”ê°€
    speechConfig.speechRecognitionLanguage = 'zh-CN';
    
    // ì—°ê²° ì„¤ì • ê°œì„ 
    speechConfig.setProperty(SpeechSDK.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs, '1000');
    speechConfig.setProperty(SpeechSDK.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs, '5000');
    
    const recognizer = new SpeechSDK.SpeechRecognizer(speechConfig, audioConfig);
    
    console.log('ğŸ¤ Azure Speech Recognition ì‹œì‘...');
    
    // ì¼ë°˜ Speech Recognitionìœ¼ë¡œ ë¨¼ì € í…ŒìŠ¤íŠ¸
    const result = await new Promise<SpeechSDK.SpeechRecognitionResult>((resolve, reject) => {
      recognizer.recognizeOnceAsync(
        (result) => resolve(result),
        (error) => reject(error)
      );
    });
    
    console.log('âœ… Azure Speech Recognition ì™„ë£Œ');
    console.log('ì¸ì‹ ê²°ê³¼:', result.text);
    
    // ì„ì‹œë¡œ ê¸°ë³¸ ì ìˆ˜ ë°˜í™˜ (Pronunciation Assessment ëŒ€ì‹ )
    const assessmentResult = {
      overallScore: 75, // ì„ì‹œ ì ìˆ˜
      accuracyScore: 80,
      fluencyScore: 70,
      completenessScore: 85,
      prosodyScore: 65,
      confidenceScore: 0,
      words: [],
      syllables: [],
      phonemes: []
    };
    
    console.log('âœ… Azure Assessment ì™„ë£Œ (ì„ì‹œ)');
    return assessmentResult;
    
  } catch (error) {
    console.error('âŒ Azure Pronunciation Assessment ì‹¤íŒ¨:', error);
    throw new Error(`Azure í‰ê°€ ì‹¤íŒ¨: ${error}`);
  }
};

// ê°•ì ê³¼ ê°œì„ ì  ë¶„ì„ (ì‹¤ì œ ì ìˆ˜ ê¸°ë°˜)
export const analyzeStrengthsAndWeaknesses = (
  accuracyScore: number,
  fluencyScore: number,
  completenessScore: number,
  prosodyScore: number
) => {
  const strongPoints: string[] = [];
  const improvementAreas: string[] = [];

  if (accuracyScore >= 80) strongPoints.push('ì •í™•í•œ ë°œìŒ');
  else if (accuracyScore < 60) improvementAreas.push('ê¸°ë³¸ ë°œìŒ ì •í™•ì„±');

  if (fluencyScore >= 80) strongPoints.push('ì¢‹ì€ ìœ ì°½ì„±');
  else if (fluencyScore < 60) improvementAreas.push('ë§í•˜ê¸° ì†ë„ì™€ ë¦¬ë“¬');

  if (completenessScore >= 80) strongPoints.push('ì™„ì „í•œ ë¬¸ì¥ êµ¬ì‚¬');
  else if (completenessScore < 60) improvementAreas.push('ë¬¸ì¥ ì™„ì„±ë„');

  if (prosodyScore >= 80) strongPoints.push('ìì—°ìŠ¤ëŸ¬ìš´ ì–µì–‘');
  else if (prosodyScore < 60) improvementAreas.push('ì„±ì¡°ì™€ ì–µì–‘');

  return { strongPoints, improvementAreas };
};

// ì ìˆ˜ë³„ ì¡°ì–¸ ìƒì„±
export const generateScoreAdvice = (overallScore: number): string => {
  if (overallScore >= 90) {
    return 'ì›ì–´ë¯¼ ìˆ˜ì¤€ì— ê·¼ì ‘í–ˆìŠµë‹ˆë‹¤! ë‹¤ì–‘í•œ ì£¼ì œë¡œ ì—°ìŠµì„ í™•ì¥í•´ë³´ì„¸ìš”.';
  } else if (overallScore >= 80) {
    return 'ë§¤ìš° ì¢‹ì€ ë°œìŒì´ì—ìš”. ì„±ì¡°ì™€ ì–µì–‘ì„ ì¡°ê¸ˆ ë” ë‹¤ë“¬ìœ¼ë©´ ì™„ë²½í•´ì§ˆ ê²ƒ ê°™ì•„ìš”.';
  } else if (overallScore >= 70) {
    return 'ì¢‹ì€ ê¸°ë°˜ì„ ê°–ì¶”ê³  ìˆì–´ìš”. ë” ë§ì€ ì—°ìŠµìœ¼ë¡œ ì™„ì„±ë„ë¥¼ ë†’ì—¬ë³´ì„¸ìš”.';
  } else if (overallScore >= 60) {
    return 'ê¸°ë³¸ê¸°ëŠ” ê°–ì¶”ì—ˆì§€ë§Œ ë” ë§ì€ ì—°ìŠµì´ í•„ìš”í•´ìš”. ì„±ì¡°ì™€ ê¸°ë³¸ ìŒì†Œë¥¼ ë°˜ë³µ ì—°ìŠµí•˜ì„¸ìš”.';
  } else {
    return 'ê¸°ì´ˆë¶€í„° ì°¨ê·¼ì°¨ê·¼ ì—°ìŠµí•´ë³´ì„¸ìš”. ì²œì²œíˆ ì •í™•í•˜ê²Œ ë°œìŒí•˜ëŠ” ê²ƒì— ì§‘ì¤‘í•˜ì„¸ìš”.';
  }
}; 